---
dlayout:    post
title:      All about Vision Transformer
subtitle:   Vision Transformer (ViT) 论文讲解
date:       2023-3-28
author:     Kylin
header-img: img/VIT.jpg
catalog: true
tags:
    - Object Detection
---



[TOC]



### Transformer in CV

#### Transformer的优势：

- 并行计算

<img src="http://kylinhub.oss-cn-shanghai.aliyuncs.com/uPic/3333xsdwqs.png" alt="3333xsdwqs" style="zoom:43%;" />

- 全局视野
- 灵活的堆叠



#### ViT的研究价值

- 展示了在计算机视觉中使用纯Transformer结构的可能

图片—〉transformer—〉 结果

图片—〉backbone(CNN) —〉transformer—〉 结果



### ViT Network Dataflow

#### Dataflow

<img src="http://kylinhub.oss-cn-shanghai.aliyuncs.com/uPic/%E6%88%AA%E5%B1%8F2023-03-30%2014.50.00-1.png" alt="截屏2023-03-30 14.50.00-1" style="zoom:67%;" />

#### Self-Attention

> 本质上是一种自相似性的计算
>
> 早期的 Attention mechanism：
>
> <img src="http://kylinhub.oss-cn-shanghai.aliyuncs.com/uPic/%E6%88%AA%E5%B1%8F2023-03-30%2015.03.48.png" alt="截屏2023-03-30 15.03.48" style="zoom:33%;" />

Transformer中的Self Attention这样计算：

<img src="http://kylinhub.oss-cn-shanghai.aliyuncs.com/uPic/%E6%88%AA%E5%B1%8F2023-03-30%2015.05.51.png" alt="截屏2023-03-30 15.05.51" style="zoom:30%;" />

Q、K、V 是从输入向量（矩阵）线性变换得到的三个向量（矩阵）；在代码层面，我们可能只是使用一次矩阵乘，然后切分成三个矩阵：

Query: 查询, 询问；**相当于你在淘宝搜索 “游戏机”**

Key: 键值，关键词 ；**相当于在后端数据库中“游戏机”**

Value: 价值，数值；**相当于商品页面的“选项”**

所以Q(K^T)相当于计算搜索词与数据库的匹配度，Q(K^T)V相当于输出搜索结果

<img src="http://kylinhub.oss-cn-shanghai.aliyuncs.com/uPic/%E6%88%AA%E5%B1%8F2023-03-30%2015.31.28.png" alt="截屏2023-03-30 15.31.28" style="zoom:39%;" />

这里的 Z1=V1+V2+V3 结果就是词语在句子背景下的词义

- 这里的向量乘可以通过矩阵乘法并行

<img src="http://kylinhub.oss-cn-shanghai.aliyuncs.com/uPic/v2-8628bf2c2bb9a7ee2c4a0fb870ab32b9_1440w.jpg" alt="v2-8628bf2c2bb9a7ee2c4a0fb870ab32b9_1440w" style="zoom:40%;" />

>  这个图里的乘法转置过



#### Multi-Head

本质上就是有多个Wq,Wk,Wv, 上述操作重复多次，结果concat一起，再过一次linear使得结果与输入维度一致。

<img src="http://kylinhub.oss-cn-shanghai.aliyuncs.com/uPic/%E6%88%AA%E5%B1%8F2023-03-30%2015.21.36.png" alt="截屏2023-03-30 15.21.36" style="zoom:47%;" />

Multi-Head使得模型可以使用多种注意力：短注意力、长注意力等



### Details

#### 为什么会有 Patch 0？

从NLP角度看，Patch 0 是一个句子的起始符，NLP认为 输出的 Cls Token 可以用在句子级语义判断上（比如句子分类问题）；

从CV角度上看，ViT 需要一个整合信息的向量，如果只有原始输出的9个向量，用哪个向量来分类都不好，全用计算量又很大（也可以，就是求均值），所以加一个可学习的 vector 也就是patch 0来整合信息。

<img src="http://kylinhub.oss-cn-shanghai.aliyuncs.com/uPic/%E6%88%AA%E5%B1%8F2023-03-30%2014.48.06.png" alt="截屏2023-03-30 14.48.06" style="zoom:80%;" />



#### Positional encoding

Motivation：图像切分重排后失去了位置信息，并且Transformer的内部运算是空间信息无关的，所以需要把位置信息编码重新传进网络

Solution：ViT使用了一个可学习的vector来编码，编码vector和patch vector直接相加组成输入

- 相加是一种特殊的 concat：

$W(I+P)=WI+W P$

$[W_1, W_2][I, P]=W_1 I+W_2 P$

$\mathrm{W} 1=\mathrm{W} 2$ 时，两式一致; 其实也有为了简化计算的原因

<img src="http://kylinhub.oss-cn-shanghai.aliyuncs.com/uPic/%E6%88%AA%E5%B1%8F2023-03-30%2015.10.43.png" alt="截屏2023-03-30 15.10.43" style="zoom:50%;" />



#### 为什么scale取sqrt(d_k)?

https://github.com/BAI-Yeqi/Statistical-Properties-of-Dot-Product/blob/master/proof.pdf































