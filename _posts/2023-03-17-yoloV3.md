---
dlayout:    post
title:      All about Yolo V3 
subtitle:   yolo V3 从论文到实现
date:       2023-3-17
author:     Kylin
header-img: img/yolov3.jpg
catalog: true
tags:
    - Object Detection
---



[TOC]



### 目标检测技术 & yolo系列介绍



#### 目标检测技术概况

##### 目标检测技术分类

- Anchor based：要在feature map上生成大量先验框，之后进行减框+精化
  - Two-stage：第一阶段提取region proposal，第二阶段精确定位+分类；RCNN，FPN
  - One-stage：直接分类和回归；YOLO，SSD，Retina-Net

- Anchor free：速度快
  - One-stage：CenterNet、CornerNet、Fcos



##### 目标检测发展历史

![截屏2023-03-18 00.10.13](http://kylinhub.oss-cn-shanghai.aliyuncs.com/uPic/%E6%88%AA%E5%B1%8F2023-03-18%2000.10.13.png)

#### yolo系列目标检测

##### yolo的原理

- m x n大小的图像图片m x n x 3 的图片化成 grid-splitted 的点 m1 x n1 x 512（512维度特征，m1、n1小于m、n）

- 每一个1x1的点产生3个anchor
- 对比 anchor 和 ground truth，产生 loss

- 输入与输出：

>如果我们有 SxS个框, 每个框的锚框 (bbox) 个数为 $B$, 分类器可以识别出 $C$ 种不同的物体, 那么整个ground truth 的维度为:（其中 5 代表的是每一个anchor需要5个量去描述：中心坐标，长宽，存在目标的置信度）
$$
\mathrm{S} \times S \times(B \times (5+C))
$$
> 同理, 网络的预测结果的维度也是:

$$
\mathrm{S} \times S \times(B \times (5+C))
$$
> 预测结果与GT进行loss计算, loss计算传播更新整 个网络的参数



##### yolo的意义

- 创造性地将检测和识别合二为一
- 检测速度极快



##### SOTA的目标检测网络结构

**backbone-neck-head**：

- backbone网络对图像特征进行提取

- neck网络对图像特征进行拼接、变换、融合

- head网络进行分类与回归



### yolo v3算法细节

#### 分类标签上的问题

yolo v3在分类标签上使用的是每一个类别使用逻辑回归（sigmid），而不是使用softmax

> 在分类模型中用sigmoid和softmax的区别:
>
> 在分类模型中，sigmoid和softmax都是用来将模型的输出转化为概率分布，从而用于分类的。
>
> Sigmoid函数可以将任意实数映射到0到1之间的一个值，公式为：
>
> $$sigmoid(x) = \frac{1}{1 + e^{-x}}$$
>
> 在二分类问题中，sigmoid函数通常被用来将模型输出映射到0到1之间的一个概率值，表示正例的概率。对于多分类问题，可以使用多个sigmoid函数来分别计算每个类别的概率。
>
> 相比之下，softmax函数则是将多个实数映射到一个概率分布上。在多分类问题中，softmax函数通常被用来将模型输出转化为每个类别的概率值，公式为：
>
> $$softmax(x_i) = \frac{e^{x_i}}{\sum_{j=1}^K e^{x_j}}$$
>
> 其中，$x_i$表示模型对第$i$个类别的得分，$K$表示类别总数。softmax函数可以保证所有类别的概率值之和为1。
>
> 因此，sigmoid函数适用于二分类问题或将多分类问题分解成多个二分类问题的情况，而softmax函数适用于多分类问题。

#### 网络结构

- backbone+neck简略概括（输入大小和原文不同）：

<img src="http://kylinhub.oss-cn-shanghai.aliyuncs.com/uPic/%E6%88%AA%E5%B1%8F2023-03-18%2000.32.09.png" alt="截屏2023-03-18 00.32.09" style="zoom:47%;" />

左侧的是backbone网络，提取不同尺度和不同维度的feature map，backbone进行的是下采样，即卷积进行的是下采样。

右侧的是neck网络，用来整合feature map

小尺度的feature map用来检测大尺度目标，大尺度feature map用来检测小尺度目标

concat指的是通道（维度）上的拼接

> 关于上采样和下采样：
>
> 目标检测中的上采样（upsampling）和下采样（downsampling）是指对输入图像进行调整大小的过程，以便将其适应于模型的输入和输出要求。
>
> 下采样是指将输入图像的分辨率降低，通常通过对图像进行卷积和池化操作来实现。这种操作可以使模型更快速地处理输入数据，但也会造成信息的丢失。下采样后得到的特征图尺寸通常比输入图像小，但具有更多的抽象信息和语义特征。
>
> 上采样是指将特征图的分辨率恢复到原始输入图像的大小，通常通过插值或反卷积等操作来实现。上采样可以恢复图像细节和准确位置信息，使得模型更能够精确地定位目标。在一些目标检测模型中，上采样是通过连接卷积层的不同特征图来实现的，这种方法被称为特征金字塔网络（Feature Pyramid Network，FPN）。

- 输入输出可视化：

![qsqsqs](http://kylinhub.oss-cn-shanghai.aliyuncs.com/uPic/qsqsqs.png)

> 用的是COCO数据集，有80个预测类



- backbone+neck+head标准网络（输入大小和原文一致）：

![截屏2023-03-19 15.57.51](http://kylinhub.oss-cn-shanghai.aliyuncs.com/uPic/%E6%88%AA%E5%B1%8F2023-03-19%2015.57.51.png)

> 1x1的卷积一般是用来改变通道数的：https://www.zhihu.com/question/56024942

> mAP-50（预测与GT的IOU大于0.5判断为正例子）是mAP中的一项
>
> mAP是 mAP-50～mAP-95的平均值

> 消融实验（ablation study）是指一种科学实验方法，其目的是通过逐步移除某个系统的组成部分来研究它们对系统整体行为的贡献。在机器学习领域中，消融实验常用于研究模型中的各个组件对性能的影响。例如，假设我们有一个分类模型，包括一个卷积神经网络和一个全连接神经网络。为了研究哪个组件对模型性能的贡献更大，我们可以通过消融实验来逐步移除这些组件，比如只使用全连接网络或只使用卷积网络，然后比较模型的性能差异。























### 代码复现&分析
