---
dlayout:    post
title:      Introduction to Mobius
subtitle:   Fine Tuning Large-Scale Models on Commodity GPU Servers
date:       2023-8-16
author:     Kylin
header-img: img/bg-owncloud.jpg
catalog: true
tags:
    - paper
---



[TOC]

> Mobius offload key insightsï¼šNote that we focus on extending GPU memory with only DRAM, since publicly available pretrained models can usually fit in DRAM and the **limited bandwidth of SSDs is a performance bottleneck on a single server.**

#### Baselineï¼š

Gpipeï¼ˆåªä½¿ç”¨GPU Memoryï¼‰ã€Deepspeedï¼ˆæœ€å…ˆè¿›çš„heterogeneous memoryè®­ç»ƒç³»ç»Ÿï¼Œä½†æ˜¯pipelineåªæ”¯æŒçº¯GPUçš„ï¼‰

#### Challengeï¼š

low **interGPU communication bandwidth** and **pressing communication contention**ï¼ˆé€šä¿¡äº‰ç”¨ï¼‰ on the commodity GPU server obstruct training efficiency

![](http://kylinhub.oss-cn-shanghai.aliyuncs.com/uPic/image-20230820151459924.png)

#### Methodï¼š

Mobius partitions the model into stages and carefully schedules them between GPU memory and DRAM to overlap communication with computation.

1ï¼‰æ€ä¹ˆåˆ†ï¼šIt formulates pipeline execution into a mixed-integer program problem to find the optimal pipeline partition.

2ï¼‰æ€ä¹ˆstage-GPUæ˜ å°„ï¼šIt also features a new stage-to-GPU mapping method termed cross mapping, to minimize communication contention.



#### Contributionï¼š

- profile existing fine-tuning systems on commodity GPU servers, and find that **communication resources is the  bottleneck** (communication)
- A proposed system, Mobius, for fine-tuning **large-scale** models on **commodity** GPU servers. (Off-the-shelf GPU)



#### Gapsï¼š

- server GPU æœ‰ NVLinkï¼Œå¸¦å®½æœ‰900G/sï¼Œè¿œè¶…PCIeçš„16G/s

- server GPU å¯ä»¥ä½¿ç”¨ GPUDirectï¼šå…¶æ ¸å¿ƒåŸç†æ˜¯ï¼šåœ¨ä¸å¿…è¦çš„æ—¶å€™é¿å…CPUçš„å‚ä¸

  GPUDirectæ˜¯NVIDIAä¸ºå…¶CUDAå¹³å°å¼•å…¥çš„ä¸€ç»„æŠ€æœ¯ï¼Œå®ƒä»¬å…è®¸ç›´æ¥æ•°æ®äº¤æ¢ä»‹äºGPUä¸å…¶ä»–è®¾å¤‡ï¼Œå¦‚å…¶ä»–GPUæˆ–ç½‘ç»œè®¾å¤‡ã€‚å…¶ä¸»è¦ç›®çš„æ˜¯é¿å…æ•°æ®åœ¨äº¤æ¢è¿‡ç¨‹ä¸­ä¸å¿…è¦åœ°é€šè¿‡ä¸»æœºå†…å­˜ï¼Œä»è€Œå‡å°‘æ•°æ®ä¼ è¾“çš„å»¶è¿Ÿå¹¶å¢åŠ ç³»ç»Ÿæ•´ä½“çš„ååé‡ã€‚

  GPUDirectçš„å‡ ä¸ªä¸»è¦éƒ¨åˆ†åŒ…æ‹¬ï¼š

  1. **GPUDirect P2P (Peer-to-Peer) Memory Access**: å…è®¸CUDAä¸Šçš„ä¸€ä¸ªGPUç›´æ¥è®¿é—®å¦ä¸€ä¸ªGPUçš„å†…å­˜ã€‚è¿™é¿å…äº†CPUä»‹å…¥å¹¶å‡å°‘äº†æ•°æ®ä¼ è¾“çš„å»¶è¿Ÿã€‚
  2. **GPUDirect RDMA (Remote Direct Memory Access)**: è¿™å…è®¸ç¬¬ä¸‰æ–¹è®¾å¤‡ï¼ˆå¦‚ç½‘ç»œé€‚é…å™¨ï¼‰ç›´æ¥è¯»å–/å†™å…¥GPUå†…å­˜ï¼Œè€Œä¸éœ€è¦CPUçš„å¹²é¢„ã€‚è¿™å¯¹äºå¤§è§„æ¨¡é«˜æ€§èƒ½è®¡ç®—ç¯å¢ƒä¸­çš„ç½‘ç»œé€šä¿¡å°¤ä¸ºæœ‰ç”¨ï¼Œå› ä¸ºå®ƒå¯ä»¥å‡å°‘é€šä¿¡çš„å»¶è¿Ÿã€‚
  3. **GPUDirect Storage**: è¿™æ˜¯ä¸€ä¸ªæ–°çš„æŠ€æœ¯ï¼Œå®ƒæ—¨åœ¨æé«˜GPUä¸NVMeå­˜å‚¨è®¾å¤‡ä¹‹é—´çš„æ•°æ®äº¤æ¢é€Ÿåº¦ã€‚ä¼ ç»Ÿä¸Šï¼ŒGPUå¤„ç†æ•°æ®æ—¶ï¼Œæ•°æ®é¦–å…ˆéœ€è¦ä»å­˜å‚¨è®¾å¤‡åŠ è½½åˆ°CPUå†…å­˜ï¼Œç„¶åå†å¤åˆ¶åˆ°GPUã€‚ä½†æ˜¯ï¼Œæœ‰äº†GPUDirect Storageï¼Œæ•°æ®å¯ä»¥ç›´æ¥ä»å­˜å‚¨è®¾å¤‡ä¼ è¾“åˆ°GPUï¼Œè·³è¿‡äº†CPUå†…å­˜ã€‚
  4. **GPUDirect for Video**: è¿™æ˜¯ä¸ºè§†é¢‘åº”ç”¨ç¨‹åºè®¾è®¡çš„ï¼Œå…è®¸è§†é¢‘è®¾å¤‡ç›´æ¥ä¸NVIDIA GPUé€šä¿¡ï¼Œä»è€Œé¿å…æ•°æ®é€šè¿‡ä¸»æœºåº”ç”¨ç¨‹åºã€‚



### Framework

3ä¸ªæ–¹é¢çš„workç»„æˆmobiusçš„ä¸€æ¡pipelineï¼š

1ï¼‰Mobius : a novel **pipeline** parallelism to **reduce communications**

2ï¼‰model **partition algorithm** based on mixed-integer programs (MIP)

3ï¼‰cross mapping to **map** stages to different GPUs and reduces **communication contention**



#### 1ï¼‰Pipeline

- Gpipe Baselineï¼š

<img src="http://kylinhub.oss-cn-shanghai.aliyuncs.com/uPic/%E6%88%AA%E5%B1%8F2023-08-20%2016.45.55.png" alt="æˆªå±2023-08-20 16.45.55" style="zoom:53%;" />

> microbatch æ˜¯æŒ‡æµæ°´çº¿å¹¶è¡Œçš„batch

- Mobiusï¼š

> è¿™é‡Œä¹Ÿå¯ä»¥çœ‹å‡ºcross mappingçš„ä½œç”¨

<img src="http://kylinhub.oss-cn-shanghai.aliyuncs.com/uPic/%E6%88%AA%E5%B1%8F2023-08-20%2017.18.38.png" alt="æˆªå±2023-08-20 17.18.38" style="zoom:100%;" />

è¿™é‡Œåˆ†æäº†è¿™ä¸ªpipelineçš„communicationTrafficï¼Œç»“è®ºæ˜¯DSéœ€è¦åœ¨æ¯ä¸€ä¸ªGPUä¸Šloadä¸€æ¬¡parametersï¼Œä½†æ˜¯Mobiusåªéœ€è¦ä¸€æ¬¡loadï¼Œæ‰€ä»¥ç»“è®ºæ˜¯costé™ä½åˆ°1/Näº†ã€‚



#### 2ï¼‰Model Partition

åˆ©ç”¨Mixed Integer Program (MIP) è§£å†³ï¼š

- å¤šå°‘stage 
- layer-stage mapping

<img src="https://kylinhub.oss-cn-shanghai.aliyuncs.com/image-20230820195634735.png" alt="image-20230820195634735" style="zoom:80%;" />

Profiling çš„æ—¶å€™åšäº†å±‚èšåˆï¼Œä¸ºäº†æ–¹ä¾¿ï¼Œä½†æ˜¯æ²¡æœ‰ç»†è¯´ç®—æ³•

MIP æ˜¯ç”¨ Gurobi åšçš„





#### 3ï¼‰Cross Mapping

Based on the observation, Mobius maps adjacent stages to GPUs not under the same CPU root complex as much as possible, called cross mapping.   

å…¶å®å°±æ˜¯å°½é‡æŠŠç›¸é‚»stageä¸è¦åˆ†é…åˆ°ä¸€ä¸ªGPUä¸Šå‘—

è¿™é‡Œæœ‰ä¸€ä¸ªäº‰ç”¨åº¦çš„æ¦‚å¿µï¼šå¯¹äº stage_i å’Œ stage_jï¼Œæœ‰ä¸¤ä¸ªè§‚å¯Ÿï¼š

1ï¼‰iå’Œjçš„ç»å¯¹å·®è¶Šå°ï¼Œäº‰ç”¨è¶Šå¤§

2ï¼‰è‹¥iå’Œjåœ¨åŒä¸€ä¸ªroot complexä¸Šï¼Œè¿æ¥çš„GPUè¶Šå¤šï¼Œäº‰ç”¨è¶Šå¤§

<img src="https://kylinhub.oss-cn-shanghai.aliyuncs.com/image-20230820202851055.png" alt="image-20230820202851055" style="zoom:67%;" />

> shğ‘ğ‘Ÿğ‘’ğ‘‘(ğ‘–, ğ‘—) is the number of GPUs under the same CPU root complex where ğ‘†ğ‘¡ğ‘ğ‘”ğ‘’ğ‘– and ğ‘†ğ‘¡ğ‘ğ‘”ğ‘’ğ‘— are located. If the GPUs storing ğ‘†ğ‘¡ğ‘ğ‘”ğ‘’ğ‘– and ğ‘†ğ‘¡ğ‘ğ‘”ğ‘’ğ‘— are under different CPU root complex, ğ‘ â„ğ‘ğ‘Ÿğ‘’ğ‘‘(ğ‘–, ğ‘—) is zero  

å› æ­¤åˆ†é…çš„ä¼˜åŒ–objectiveä¸ºï¼š

<img src="https://kylinhub.oss-cn-shanghai.aliyuncs.com/image-20230820203002867.png" alt="image-20230820203002867" style="zoom:67%;" />

mobius æ˜¯æšä¸¾ä¹‹åè¿›è¡Œæœ€å°åŒ–çš„

è¿˜æœ‰ä¸€ä¸ªtrickæ˜¯å¦‚æœprefetchäº‰ç”¨äº†ï¼Œé‚£ä¸ªstageå…ˆæ‰§è¡Œå°±ç»™å®ƒèµ‹äºˆé«˜æƒé™ï¼ˆcudaStreamCreateWithPriorityï¼‰ï¼Œç›®æ ‡æ˜¯é¿å…ä¹‹åæ›´å¤šçš„æµæ°´çº¿é˜»å¡ã€‚



### Evaluation

#### Setupï¼š

ï¼ˆfirst setupï¼‰1.5TB DRAM, two Intel Xeon Gold 6130 CPUs and 8Ã—3090-Tiã€‚Every 4 GPUs are connected to a CPU root complex via PCIe 3.0x8 and a PCIe Switchã€‚

ï¼ˆsecond setupï¼‰EC2 P3.8xlarge instanceï¼Œprovides 4Ã—V100 GPUs (16 GB memory) and enables GPUDirect P2P via NVLink with bandwidth of 300 GB/s.

å¹¶ä¸”å°è¯•ä¸åŒçš„GPUæ‹“æ‰‘ï¼Œè¿™ä¼šå½±å“ communication contention

**The 3B model with batch size of 2 is the largest model that GPipe and DeepSpeed with pipeline parallelism can train**

GPipeå’ŒDSä¸èƒ½å®Œå…¨é€‚åº”offloadï¼Œå› æ­¤å®éªŒæœ‰å¾ˆå¤šå¦¥åã€‚



#### Metricsï¼š

å¸¦å®½CDF

æ¯ä¸€ä¸ªstepè®­ç»ƒæ—¶é—´



























